{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanVsAIPong:\n",
    "    def __init__(self):\n",
    "        # Initialize game parameters\n",
    "        self.width = 400  # Match original training width\n",
    "        self.height = 400  # Match original training height\n",
    "        self.paddle_width = 10  # Match training paddle width\n",
    "        self.paddle_height = 60  # Match training paddle height\n",
    "        self.ball_size = 10\n",
    "        self.paddle_speed = 5  # Match training speed\n",
    "        self.ball_speed = 5    # Match training speed\n",
    "        \n",
    "         # AI performance parameters\n",
    "        self.ai_update_frequency = 1  # Update every frame for better performance\n",
    "        self.prediction_threshold = 0.8  # Confidence threshold for actions\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        # Initialize positions\n",
    "        self.human_paddle_pos = self.height // 2\n",
    "        self.ai_paddle_pos = self.height // 2\n",
    "        self.ball_pos = [self.width // 2, self.height // 2]\n",
    "        self.ball_direction = [1, 1]\n",
    "        \n",
    "        # Initialize scores\n",
    "        self.human_score = 0\n",
    "        self.ai_score = 0\n",
    "        \n",
    "        # Initialize Pygame\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Human vs AI Pong\")\n",
    "        self.clock = pygame.time.Clock()\n",
    "        \n",
    "        # Initialize font\n",
    "        self.font = pygame.font.Font(None, 74)\n",
    "        \n",
    "    def get_ai_state(self):\n",
    "        # Convert game state to AI input format\n",
    "        return np.array([\n",
    "            self.ai_paddle_pos / self.height,\n",
    "            self.ball_pos[1] / self.height,\n",
    "            (self.width - self.ball_pos[0]) / self.width,  # Flip x-coordinate for AI\n",
    "            -self.ball_direction[0],  # Flip x-direction for AI\n",
    "            self.ball_direction[1]\n",
    "        ])\n",
    "    \n",
    "    def reset_ball(self, direction):\n",
    "        self.ball_pos = [self.width // 2, self.height // 2]\n",
    "        self.ball_direction = [direction, random.uniform(-1, 1)]\n",
    "        self.normalize_ball_direction()\n",
    "    \n",
    "    def normalize_ball_direction(self):\n",
    "        # Normalize ball direction vector\n",
    "        length = np.sqrt(self.ball_direction[0]**2 + self.ball_direction[1]**2)\n",
    "        self.ball_direction = [self.ball_direction[0]/length, self.ball_direction[1]/length]\n",
    "    \n",
    "    def update(self, ai_model):\n",
    "        # Handle events and human input\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                return False\n",
    "            \n",
    "        keys = pygame.key.get_pressed()\n",
    "        if keys[pygame.K_w]:\n",
    "            self.human_paddle_pos = max(self.paddle_height // 2,\n",
    "                                      self.human_paddle_pos - self.paddle_speed)\n",
    "        if keys[pygame.K_s]:\n",
    "            self.human_paddle_pos = min(self.height - self.paddle_height // 2,\n",
    "                                      self.human_paddle_pos + self.paddle_speed)\n",
    "        \n",
    "        # Update AI paddle\n",
    "        if self.frame_count % self.ai_update_frequency == 0:\n",
    "            state = torch.FloatTensor(self.get_ai_state()).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                action = ai_model(state).max(1)[1].item()\n",
    "                \n",
    "            if action == 1:  # Move up\n",
    "                self.ai_paddle_pos = max(self.paddle_height // 2,\n",
    "                                       self.ai_paddle_pos - self.paddle_speed)\n",
    "            elif action == 2:  # Move down\n",
    "                self.ai_paddle_pos = min(self.height - self.paddle_height // 2,\n",
    "                                       self.ai_paddle_pos + self.paddle_speed)\n",
    "        \n",
    "        # Update ball position\n",
    "        self.ball_pos[0] += self.ball_speed * self.ball_direction[0]\n",
    "        self.ball_pos[1] += self.ball_speed * self.ball_direction[1]\n",
    "        \n",
    "        # Ball collision with top and bottom\n",
    "        if self.ball_pos[1] <= 0 or self.ball_pos[1] >= self.height:\n",
    "            self.ball_direction[1] *= -1\n",
    "        \n",
    "        # Ball collision with paddles\n",
    "        # Human paddle\n",
    "        if (self.ball_pos[0] <= self.paddle_width + self.ball_size//2 and\n",
    "            abs(self.ball_pos[1] - self.human_paddle_pos) < self.paddle_height // 2):\n",
    "            self.ball_direction[0] *= -1\n",
    "            # Add some randomness to bounce\n",
    "            self.ball_direction[1] += random.uniform(-0.2, 0.2)\n",
    "            self.normalize_ball_direction()\n",
    "        \n",
    "        # AI paddle\n",
    "        if (self.ball_pos[0] >= self.width - self.paddle_width - self.ball_size//2 and\n",
    "            abs(self.ball_pos[1] - self.ai_paddle_pos) < self.paddle_height // 2):\n",
    "            self.ball_direction[0] *= -1\n",
    "            # Add some randomness to bounce\n",
    "            self.ball_direction[1] += random.uniform(-0.2, 0.2)\n",
    "            self.normalize_ball_direction()\n",
    "        \n",
    "        # Score points\n",
    "        if self.ball_pos[0] <= 0:\n",
    "            self.ai_score += 1\n",
    "            self.reset_ball(1)  # Ball moves towards human\n",
    "        elif self.ball_pos[0] >= self.width:\n",
    "            self.human_score += 1\n",
    "            self.reset_ball(-1)  # Ball moves towards AI\n",
    "        \n",
    "        self.frame_count += 1\n",
    "        return True\n",
    "    \n",
    "    def render(self):\n",
    "        # Clear screen\n",
    "        self.screen.fill((0, 0, 0))\n",
    "        \n",
    "        # Draw paddles\n",
    "        pygame.draw.rect(self.screen, (255, 255, 255),\n",
    "                        (0, self.human_paddle_pos - self.paddle_height // 2,\n",
    "                         self.paddle_width, self.paddle_height))\n",
    "        pygame.draw.rect(self.screen, (255, 255, 255),\n",
    "                        (self.width - self.paddle_width,\n",
    "                         self.ai_paddle_pos - self.paddle_height // 2,\n",
    "                         self.paddle_width, self.paddle_height))\n",
    "        \n",
    "        # Draw ball\n",
    "        pygame.draw.circle(self.screen, (255, 255, 255),\n",
    "                         (int(self.ball_pos[0]), int(self.ball_pos[1])),\n",
    "                         self.ball_size // 2)\n",
    "        \n",
    "        # Draw center line\n",
    "        pygame.draw.line(self.screen, (255, 255, 255),\n",
    "                        (self.width // 2, 0),\n",
    "                        (self.width // 2, self.height),\n",
    "                        2)\n",
    "        \n",
    "        # Draw scores\n",
    "        human_text = self.font.render(str(self.human_score), True, (255, 255, 255))\n",
    "        ai_text = self.font.render(str(self.ai_score), True, (255, 255, 255))\n",
    "        self.screen.blit(human_text, (self.width // 4, 20))\n",
    "        self.screen.blit(ai_text, (3 * self.width // 4, 20))\n",
    "        \n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(60)\n",
    "    \n",
    "    def close(self):\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(base_model_path, episodes=100, learning_rate=0.0001):\n",
    "    \"\"\"Retrain an existing model to improve its performance\"\"\"\n",
    "    # Load the existing model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = DQN(5, 3).to(device)\n",
    "    model.load_state_dict(torch.load(base_model_path))\n",
    "    \n",
    "    # Create optimizer with lower learning rate for fine-tuning\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    memory = ReplayBuffer(10000)\n",
    "    \n",
    "    # Create environment\n",
    "    env = PongEnv()\n",
    "    \n",
    "    # Training parameters\n",
    "    gamma = 0.99\n",
    "    batch_size = 64\n",
    "    epsilon = 0.1  # Lower epsilon for more exploitation\n",
    "    \n",
    "    try:\n",
    "        scores = []\n",
    "        for episode in range(episodes):\n",
    "            state = env.reset()\n",
    "            score = 0\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                # Select action with lower exploration\n",
    "                if random.random() > epsilon:\n",
    "                    with torch.no_grad():\n",
    "                        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "                        action = model(state_tensor).max(1)[1].item()\n",
    "                else:\n",
    "                    action = random.randrange(3)\n",
    "                \n",
    "                # Take action\n",
    "                next_state, reward, done = env.step(action)\n",
    "                score += reward\n",
    "                \n",
    "                # Store transition\n",
    "                memory.push(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                \n",
    "                # Train if enough samples\n",
    "                if len(memory) >= batch_size:\n",
    "                    states, actions, rewards, next_states, dones = memory.sample(batch_size)\n",
    "                    \n",
    "                    states = torch.FloatTensor(states).to(device)\n",
    "                    actions = torch.LongTensor(actions).to(device)\n",
    "                    rewards = torch.FloatTensor(rewards).to(device)\n",
    "                    next_states = torch.FloatTensor(next_states).to(device)\n",
    "                    dones = torch.FloatTensor(dones).to(device)\n",
    "                    \n",
    "                    # Compute Q values\n",
    "                    current_q = model(states).gather(1, actions.unsqueeze(1))\n",
    "                    next_q = model(next_states).max(1)[0].detach()\n",
    "                    target_q = rewards + gamma * next_q * (1 - dones)\n",
    "                    \n",
    "                    # Compute loss and update\n",
    "                    loss = nn.MSELoss()(current_q.squeeze(), target_q)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            scores.append(score)\n",
    "            if episode % 10 == 0:\n",
    "                print(f\"Episode: {episode}, Score: {score}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted\")\n",
    "    finally:\n",
    "        env.close()\n",
    "    \n",
    "    # Save the retrained model with a new name\n",
    "    new_model_path = base_model_path.replace('.pth', '_retrained.pth')\n",
    "    torch.save(model.state_dict(), new_model_path)\n",
    "    return new_model_path, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_vs_ai(model_path):\n",
    "    # Load the AI model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ai_model = DQN(5, 3).to(device)\n",
    "    ai_model.load_state_dict(torch.load(model_path))\n",
    "    ai_model.eval()\n",
    "    \n",
    "    # Create game environment\n",
    "    env = HumanVsAIPong()\n",
    "    \n",
    "    print(\"Controls:\")\n",
    "    print(\"W - Move paddle up\")\n",
    "    print(\"S - Move paddle down\")\n",
    "    print(\"Close window to quit\")\n",
    "    \n",
    "    try:\n",
    "        running = True\n",
    "        while running:\n",
    "            running = env.update(ai_model)\n",
    "            env.render()\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print(\"\\nGame ended\")\n",
    "    finally:\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyain\\AppData\\Local\\Temp\\ipykernel_12496\\3290025718.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ai_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls:\n",
      "W - Move paddle up\n",
      "S - Move paddle down\n",
      "Close window to quit\n"
     ]
    }
   ],
   "source": [
    "play_vs_ai('pong_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
